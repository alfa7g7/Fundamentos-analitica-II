{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de la margen débil con máquinas vectores de soporte también se puede aplicar para problemas de regresión. La clase correspondiente en **scikit-learn** es **SVR**, que encuentra un \"tubo\" que incluya la mayor cantidad de puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación de datasets sintéticos aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action=‘ignore’,category=DeprecationWarning)\n",
    "#warnings.filterwarnings(action=‘ignore’,category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear dos datasets von un mismo proceso generador, utilizando una base sinusoidal, a la que le vamos a agregar ruido para volverla más interesante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "num_puntos_train = 1000\n",
    "num_puntos = 200\n",
    "ruido_uniforme_agregado = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [],[]\n",
    "for i in range(num_puntos):\n",
    "    a = i/10+random.uniform(-ruido_uniforme_agregado,ruido_uniforme_agregado)\n",
    "    yy = math.sin(a)+3+random.uniform(-ruido_uniforme_agregado,ruido_uniforme_agregado)\n",
    "    X_train.append([a])\n",
    "    y_train.append([yy])  \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(124)\n",
    "X_test, y_test = [],[]\n",
    "for i in range(num_puntos):\n",
    "    a = i/10+random.uniform(-ruido_uniforme_agregado,ruido_uniforme_agregado)\n",
    "    yy = math.sin(a)+3+random.uniform(-ruido_uniforme_agregado,ruido_uniforme_agregado)\n",
    "    X_test.append([a])\n",
    "    y_test.append([yy])  \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"training\")\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"test\")\n",
    "plt.legend()\n",
    "_=plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento de modelo SVM de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar la clase **SVR**, del paquete scikit-learn.\n",
    "Para la instanciación, hay que especificar los mismos parámetros que con un clasificador, particularmente:\n",
    "\n",
    "- *C*: valor de la penalidad de una instancia por violación de las márgenes (1 por defecto); controla la regularización. A menor valor de C, mayor amplitud de la margen del \"tubo\" de regresión\n",
    "- *kernel*: el tipo de kernel a utilizar ('rbf' por defecto); otros valores aceptados son: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’.\n",
    "- *degree*: grado del polinomio en el caso del kernel 'poly' (3 por defecto); se ignora para otros kernels.\n",
    "- *gamma*: determina la dispersión alrededor de los vectores de soporte ('auto' por defecto); solo se considera para los kernels ‘rbf’, ‘poly’ y ‘sigmoid’. Por defecto, *gamma* es igual a 1/m, donde m es el número de dimensiones. A mayor *gamma*, más complejo será el espacio de representación de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.1\n",
    "modelo = SVR(C=C, kernel='rbf')\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción se hace a través del método **predict**, que recibe un array con los valores de las variables predictivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver como quedan los resultados predichos por el modelo de regresión, comparándolos a los datos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"real\")\n",
    "plt.scatter(X_test, y_pred, c=\"r\", label=\"predicho\")\n",
    "plt.title(\"SVR con RBF y un valor de C de {}\".format(C) )\n",
    "plt.legend()\n",
    "_=plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos la calidad del modelo. Vamos a utilizar el método **score**, que nos retorna el R2 de las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=modelo.score(X_train, y_train)\n",
    "print(\"R2=\", score)\n",
    "\n",
    "mse =mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentemos con un mayor valor de *C*, para entender mejor la influencia del parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=1\n",
    "modelo = SVR(C=C, kernel='rbf')\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"real\")\n",
    "plt.scatter(X_test, y_pred, c=\"r\", label=\"predicho\")\n",
    "plt.legend()\n",
    "plt.title(\"SVR con RBF y un valor de C de {}\".format(C) )\n",
    "_=plt.show()\n",
    "\n",
    "score=modelo.score(X_train, y_train)\n",
    "print(\"R2=\", score)\n",
    "mse =mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=10\n",
    "modelo = SVR(C=C, kernel='rbf')\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"real\")\n",
    "plt.scatter(X_test, y_pred, c=\"r\", label=\"predicho\")\n",
    "plt.legend()\n",
    "plt.title(\"SVR con RBF y un valor de C de {}\".format(C) )\n",
    "_=plt.show()\n",
    "\n",
    "score=modelo.score(X_train, y_train)\n",
    "print(\"R2=\", score)\n",
    "mse =mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = SVR(C=10, kernel='rbf')\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"real\")\n",
    "plt.scatter(X_test, y_pred, c=\"r\", label=\"predicho\")\n",
    "plt.legend()\n",
    "_=plt.show()\n",
    "\n",
    "score=modelo.score(X_train, y_train)\n",
    "print(\"R2=\", score)\n",
    "mse =mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=100\n",
    "modelo = SVR(C=C, kernel='rbf')\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"real\")\n",
    "plt.scatter(X_test, y_pred, c=\"r\", label=\"predicho\")\n",
    "plt.legend()\n",
    "plt.title(\"SVR con RBF y un valor de C de {}\".format(C) )\n",
    "_=plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrica = 'neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"SVR_linear\", SVR(kernel=\"linear\"))]\n",
    "pipeline = Pipeline(steps)\n",
    "parametros = {'SVR_linear__C':[0.01,0.05,0.1,0.5,1,5,10]}\n",
    "grid1 = GridSearchCV(pipeline, param_grid=parametros, cv=5, scoring=metrica)\n",
    "grid1.fit(X_train, y_train)\n",
    "print(\"score = %3.4f\" %(grid1.score(X_test,y_test)))\n",
    "print(grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"SVR_rbf\", SVR(kernel=\"rbf\"))]\n",
    "pipeline = Pipeline(steps)\n",
    "parametros = {'SVR_rbf__C':[0.01,0.05,0.1,0.5,1,5,10], 'SVR_rbf__gamma':[0.01,0.05,0.09,1,1.05,2,5]} \n",
    "grid2 = GridSearchCV(pipeline, param_grid=parametros, cv=5, scoring=metrica)\n",
    "grid2.fit(X_train, y_train)\n",
    "print(\"score = %3.4f\" %(grid2.score(X_test,y_test)))\n",
    "print(grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"SVR_sigmoid\", SVR(kernel=\"sigmoid\"))]\n",
    "pipeline = Pipeline(steps)\n",
    "parametros = {'SVR_sigmoid__C':[0.01,0.05,0.1,0.5,1,5,10], 'SVR_sigmoid__gamma':[0.05,0.01, 1, 5]}\n",
    "grid3 = GridSearchCV(pipeline, param_grid=parametros, cv=5, scoring=metrica)\n",
    "grid3.fit(X_train, y_train)\n",
    "print(\"score = %3.4f\" %(grid3.score(X_test,y_test)))\n",
    "print(grid3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que el mejor modelo es con un kernel **rbf**, con un valor de gamma de 1. Ya lo habíamos analizado anteriormente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
