{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zR3Vib7hkLkC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ufiaTOV4ka2b"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwa23o9cwW7E"
      },
      "source": [
        "Definimos un módulo recurrente, con una única capa con 2 neuronas, que se conecta con 5 neuronas (features) de entrada.\n",
        "Veamos como quedan sus parámetros."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param, value in rnn_layer.named_parameters():\n",
        "    print(f\"{param}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgEBh1vswolq",
        "outputId": "0f679de4-79cd-427e-b148-5e8584408497"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0: Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121, -0.1371,  0.3319, -0.6657],\n",
            "        [ 0.4241, -0.1455,  0.3597,  0.0983, -0.0866]], requires_grad=True)\n",
            "weight_hh_l0: Parameter containing:\n",
            "tensor([[ 0.1961,  0.0349],\n",
            "        [ 0.2583, -0.2756]], requires_grad=True)\n",
            "bias_ih_l0: Parameter containing:\n",
            "tensor([-0.0516, -0.0637], requires_grad=True)\n",
            "bias_hh_l0: Parameter containing:\n",
            "tensor([ 0.1025, -0.0028], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhJjprp8kSNJ",
        "outputId": "13e22fe9-66c4-4bb0-a101-0a69b683ee61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_xh shape: torch.Size([2, 5])\n",
            "W_hh shape: torch.Size([2, 2])\n",
            "b_xh shape: torch.Size([2])\n",
            "b_hh shape: torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "w_xh = rnn_layer.weight_ih_l0\n",
        "w_hh = rnn_layer.weight_hh_l0\n",
        "b_xh = rnn_layer.bias_ih_l0\n",
        "b_hh = rnn_layer.bias_hh_l0\n",
        "print('W_xh shape:', w_xh.shape)\n",
        "print('W_hh shape:', w_hh.shape)\n",
        "print('b_xh shape:', b_xh.shape)\n",
        "print('b_hh shape:', b_hh.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2p3-s7EwW7F"
      },
      "source": [
        "Vemos que tenemos:\n",
        "- una matriz con los pesos que unen las 2 neuronas con los 5 inputs.\n",
        "- una matriz con los pesos de los estados anteriores de las 2 neuronas con ellas mismas en el paso actual.\n",
        "- los 2 sesgos de las conexiones de entrada (uno para cada neurona)\n",
        "- los 2 sesgos de las conexiones recurrentes (uno para cada neurona)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ifAgnN_mBMz"
      },
      "source": [
        "Creamos una única instancia con una secuencia 3 pasos de tiempo, con los datos de 5 features (e.g. temperatura, presión, precipitación)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuP2TCpdkj2B",
        "outputId": "c46dafae-66ce-4dc9-be31-cb7ed1b943e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [2., 2., 2., 2., 2.],\n",
            "        [3., 3., 3., 3., 3.]])\n",
            "torch.Size([3, 5])\n"
          ]
        }
      ],
      "source": [
        "## secuencia de una instancia, con 3 pasos de tiempo, con 5 features de entrada\n",
        "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
        "print(x_seq)\n",
        "print(x_seq.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8sentCsmMMV"
      },
      "source": [
        "Necesitamos crear el eje del batch que espera toda capa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8YtRSWl7km",
        "outputId": "6c1da29a-ba56-483d-e6f0-bf7eb7f215be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1., 1.],\n",
              "         [2., 2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3., 3.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.reshape(x_seq, (1, 3, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfLZY4FLwW7G"
      },
      "source": [
        "Vamos a procesar ese batch (de **1 única instancia**) a través del módulo recurrente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1-YbES_kw5E",
        "outputId": "a3623870-6979-43d4-c47c-ac549a78be4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.3520,  0.5253],\n",
            "         [-0.6842,  0.7607],\n",
            "         [-0.8649,  0.9047]]], grad_fn=<TransposeBackward1>)\n",
            "torch.Size([1, 3, 2])\n",
            "tensor([[[-0.8649,  0.9047]]], grad_fn=<StackBackward0>)\n",
            "torch.Size([1, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "## output of the simple RNN:\n",
        "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))\n",
        "print(output)\n",
        "print(output.shape)\n",
        "print(hn)\n",
        "print(hn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiEQ2eoll4fE"
      },
      "source": [
        "El procesamiento del batch (de 1 única instancia) produce dos tensores:\n",
        "- un **tensor de salidas**: La única capa recurrente tiene dos neuronas, la secuencia tiene un largo de 3 pasos. El tensor de salida incluirá la secuencia de los outputs progresivos de los 3 pasos. Es por eso que tiene una organización [batch=1, pasos=3, neuronas=2]\n",
        "- un **tensor de estados escondidos**, con el último valor de salida de la celda, pero con el mismo rango."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmMVoHQmkz50"
      },
      "source": [
        "Podemos hacer el proceso a pie.\n",
        "Veamoslo para el primer paso de tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHuTcADawW7G",
        "outputId": "395ad294-1590-4c1a-85ac-bbc667955c13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.reshape(x_seq[0], (1, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk4vwMxbwW7G",
        "outputId": "28707508-9759-4cfc-81e4-a001ed4809b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0516, -0.0637], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "b_xh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[i.item() for i in b_xh]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gjsbPyJM7MV",
        "outputId": "e0607f01-9903-4e8a-d034-01efd9bc087f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.051554277539253235, -0.0636589378118515]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsvNDOScwW7G",
        "outputId": "ab4ca5de-280e-4f45-d977-164795953cac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1024908497929573, -0.002824766095727682]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "[i.item() for i in b_hh]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[i.detach().numpy() for i in w_hh]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8-9LV7bMtTM",
        "outputId": "da2a9b9c-62d5-47e6-af7d-7b139e8aaf44"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.19612378, 0.03488284], dtype=float32),\n",
              " array([ 0.2582553 , -0.27556023], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LYIRQ7lskHJ",
        "outputId": "557a112a-3e27-491a-b36c-3f32ef94f32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:\n",
            " tensor([[1., 1., 1., 1., 1.]])\n",
            "matriz Wxh:\n",
            " Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121, -0.1371,  0.3319, -0.6657],\n",
            "        [ 0.4241, -0.1455,  0.3597,  0.0983, -0.0866]], requires_grad=True)\n",
            "matriz Wxh transpuesta:\n",
            " tensor([[ 0.3643,  0.4241],\n",
            "        [-0.3121, -0.1455],\n",
            "        [-0.1371,  0.3597],\n",
            "        [ 0.3319,  0.0983],\n",
            "        [-0.6657, -0.0866]], grad_fn=<TransposeBackward0>)\n",
            "sesgos bxh:\n",
            " Parameter containing:\n",
            "tensor([-0.0516, -0.0637], requires_grad=True)\n",
            "\n",
            "comb lineal x*Wxh + bhh:\n",
            " tensor([[-0.4702,  0.5864]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "paso=0\n",
        "\n",
        "# input del primer paso\n",
        "xt = torch.reshape(x_seq[0], (1, 5))\n",
        "print(\"input:\\n\", xt)\n",
        "print(\"matriz Wxh:\\n\", w_xh)\n",
        "print(\"matriz Wxh transpuesta:\\n\", torch.transpose(w_xh, 0, 1))\n",
        "print(\"sesgos bxh:\\n\",b_xh)\n",
        "# ht combinación lineal: x*Wxh + bxh\n",
        "ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
        "print(\"\\ncomb lineal x*Wxh + bhh:\\n\", ht)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d888be34-8dad-4d1a-cd61-d9e59cb053f7",
        "id": "60E-4GaxwW7G"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "input ht-1:\n",
            " tensor([[0., 0.]])\n",
            "matriz Whh transpuesta:\n",
            " tensor([[ 0.1961,  0.2583],\n",
            "        [ 0.0349, -0.2756]], grad_fn=<TransposeBackward0>)\n",
            "sesgos bhh:\n",
            " Parameter containing:\n",
            "tensor([ 0.1025, -0.0028], requires_grad=True)\n",
            "\n",
            "salida combinación lineal:\n",
            " tensor([[-0.3677,  0.5836]], grad_fn=<AddBackward0>)\n",
            "salida activación:\n",
            " tensor([[-0.3520,  0.5253]], grad_fn=<TanhBackward0>)\n"
          ]
        }
      ],
      "source": [
        "prev_h = torch.zeros((ht.shape))\n",
        "print(\"\\ninput ht-1:\\n\", prev_h)\n",
        "print(\"matriz Whh transpuesta:\\n\", torch.transpose(w_hh, 0, 1))\n",
        "print(\"sesgos bhh:\\n\",b_hh)\n",
        "# salida\n",
        "ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
        "print(\"\\nsalida combinación lineal:\\n\", ot)\n",
        "ot = torch.tanh(ot)\n",
        "print(\"salida activación:\\n\", ot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-2CuJedzLLz"
      },
      "source": [
        "Vamos a hacerlo para la secuencia de 3 pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaegM7kmkqOw",
        "outputId": "5cedb670-21fa-40a6-f050-f47227d6aebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time step 0 =>\n",
            " Input : [[1. 1. 1. 1. 1.]]\n",
            "   Hidden : [[-0.4701929   0.58639044]]\n",
            "   prev : [[0. 0.]]\n",
            "   hh : [[ 0.10249085 -0.00282477]]\n",
            "\n",
            " Output (manual) : [[-0.3519801   0.52525216]]\n",
            " RNN output : [[-0.3519801   0.52525216]]\n",
            "\n",
            "Time step 1 =>\n",
            " Input : [[2. 2. 2. 2. 2.]]\n",
            "   Hidden : [[-0.88883156  1.2364398 ]]\n",
            "   prev : [[-0.3519801   0.52525216]]\n",
            "   hh : [[ 0.05178148 -0.2384641 ]]\n",
            "\n",
            " Output (manual) : [[-0.68424344  0.76074266]]\n",
            " RNN output : [[-0.68424344  0.76074266]]\n",
            "\n",
            "Time step 2 =>\n",
            " Input : [[3. 3. 3. 3. 3.]]\n",
            "   Hidden : [[-1.3074702  1.8864892]]\n",
            "   prev : [[-0.68424344  0.76074266]]\n",
            "   hh : [[-0.0051687 -0.3891647]]\n",
            "\n",
            " Output (manual) : [[-0.8649416  0.9046636]]\n",
            " RNN output : [[-0.8649416  0.9046636]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## manually computing the output:\n",
        "out_man = []\n",
        "for t in range(3):\n",
        "    xt = torch.reshape(x_seq[t], (1, 5))\n",
        "    print(f'Time step {t} =>')\n",
        "    print(' Input :', xt.numpy())\n",
        "\n",
        "    ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
        "    print('   Hidden :', ht.detach().numpy())\n",
        "\n",
        "    if t > 0:\n",
        "        prev_h = out_man[t-1]\n",
        "    else:\n",
        "        prev_h = torch.zeros((ht.shape))\n",
        "\n",
        "    print('   prev :', prev_h.detach().numpy())\n",
        "    # print('   w_hh :', torch.transpose(w_hh, 0, 1))\n",
        "    # print('   out_man :', out_man)\n",
        "    # print('   b_hh :', b_hh.detach().numpy())\n",
        "    temp = torch.matmul(prev_h, torch.transpose(w_hh, 0, 1))  + b_hh\n",
        "    print('   hh :', temp.detach().numpy())\n",
        "\n",
        "\n",
        "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
        "    ot = torch.tanh(ot)\n",
        "    out_man.append(ot)\n",
        "    print('\\n Output (manual) :', ot.detach().numpy())\n",
        "    print(' RNN output :', output[:, t].detach().numpy())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuJ_8o9Ikd4P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}