{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Red-neuronal-artificial-desde-cero-en-Numpy---Problema-del-XOR\" data-toc-modified-id=\"Red-neuronal-artificial-desde-cero-en-Numpy---Problema-del-XOR-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Red neuronal artificial desde cero en Numpy - Problema del XOR</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inicialización-de-los-parámetros\" data-toc-modified-id=\"Inicialización-de-los-parámetros-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Inicialización de los parámetros</a></span></li><li><span><a href=\"#Feed-Forward\" data-toc-modified-id=\"Feed-Forward-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Feed Forward</a></span></li><li><span><a href=\"#Función-de-costo\" data-toc-modified-id=\"Función-de-costo-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Función de costo</a></span></li><li><span><a href=\"#Función-de-backpropagation\" data-toc-modified-id=\"Función-de-backpropagation-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Función de backpropagation</a></span></li><li><span><a href=\"#Una-iteración-de-entrenamiento\" data-toc-modified-id=\"Una-iteración-de-entrenamiento-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Una iteración de entrenamiento</a></span></li><li><span><a href=\"#Ciclo-de-entrenamiento\" data-toc-modified-id=\"Ciclo-de-entrenamiento-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Ciclo de entrenamiento</a></span></li><li><span><a href=\"#Encontrar-el-mejor-learning-rate\" data-toc-modified-id=\"Encontrar-el-mejor-learning-rate-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Encontrar el mejor learning rate</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal artificial desde cero en Numpy - Problema del XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezcla entre los videos de Siraj Raval y de Andrew Ng\n",
    "- https://www.youtube.com/watch?v=vcZub77WvFA\n",
    "- https://www.youtube.com/watch?v=262XJe2I2D0\n",
    "- https://www.coursera.org/learn/neural-networks-deep-learning/lecture/6dDj7/backpropagation-intuition-optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un clasificador binario que podrá aprender la solución a la operación de XOR, utilizando una red neuronal artificial con una capa escondida que sigue la estructura presentada en la siguiente imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"09-01-TradANNDesdeCero.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar el procedimiento de back-propagation vamos a utilizar solamente funciones activación sigmoide, y vamos a utilizar numpy para ilustrar las operaciones matemáticas matriciales básicas con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función sigmoide y su función gradiente basada en si misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoideGrad(x): # x en este caso es el valor de la función sigmoide\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos datos sintéticos (XOR sobre las dos primeras columnas) y especificamos los parámetros de la red neuronal. Incluimos una tercera columna para mostrar que la red resultante aprende a ignorar los atributos que no son importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[0 0 1 1 0 0 1 1]\n",
      " [0 1 0 1 0 1 0 1]\n",
      " [1 1 1 1 0 0 0 0]]\n",
      "y [0 1 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Queremos que cada dato registro sea un vector de 3 posiciones. \n",
    "# Tenemos aquí 8 registros apilados horizontalmente gracias a la transposición del array incialmente creado\n",
    "X = np.transpose(np.array([\n",
    "    [0,0,1],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,1],\n",
    "    [0,0,0],\n",
    "    [0,1,0],\n",
    "    [1,0,0],\n",
    "    [1,1,0]\n",
    "]))\n",
    "print(\"X\", X)\n",
    "\n",
    "y = np.array([\n",
    "    0, \n",
    "    1, \n",
    "    1, \n",
    "    0,\n",
    "    0, \n",
    "    1, \n",
    "    1, \n",
    "    0])\n",
    "print(\"y\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos los pesos de la red aleatoriamente para la capa intermedia (1) y la capa de salida (2). La capa inicial no tiene pesos pues consiste únicamente de los datos de entrada.\n",
    "\n",
    "La primera capa tiene 4 neuronas y 3 inputs, creamos una matriz de pesos w1 con 4 filas y 3 columnas. Tenemos además un vector b1 con 4 posiciones.\n",
    "\n",
    "La segunda capa tiene 1 neurona y 4 inputs, creamos una matriz de pesos w2 con 1 fila y 4 columnas. Tenemos además un vector b2 con 1 posición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParams():\n",
    "    np.random.seed(123456)\n",
    "\n",
    "    w1 = 2*np.random.random((4, 3))-1\n",
    "    w2 = 2*np.random.random((1, 4))-1\n",
    "    b1 = np.zeros((4,1))\n",
    "    b2 = np.zeros((1,1))\n",
    "    return(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: {[[-0.74606033  0.93343568 -0.47904799]\n",
      " [ 0.79447305 -0.24650057 -0.32755651]\n",
      " [-0.09724706  0.68051017 -0.75379571]\n",
      " [ 0.0860524  -0.25397555 -0.10400635]]}\n",
      "b1: {[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]}\n",
      "w2: {[[-0.74111864  0.71975741  0.64077673 -0.29589292]]}\n",
      "b2: {[[0.]]}\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = initParams()\n",
    "print(\"w1: {%s}\\nb1: {%s}\" % (w1, b1))\n",
    "print(\"w2: {%s}\\nb2: {%s}\" % (w2, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los pesos de toda la red definidos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada época, el proceso debe pasar los datos del dataset por las capas, propagando la información hacia adelante a través de las funciones de activación. Veamos como funciona esto en un primer paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "por convención las \"activaciones\" de la capa de entrada son los mismos valores de las instancias de entrenamiento. Por eso definimos a0=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = X # matriz de 3 filas (inputs) * 8 columnas (registros)\n",
    "a0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para pasar la información a través de una capa, vamos a realizar la combinación lineal de las salidas de la capa anterior (producto punto de dos vectores, los **a**'s anteriores y los **w**'s de los pesos de la capa) y a pasar el resultado por una función de activación no lineal (en este caso la sigmoide), teniendo como salida los **a**'s de la cpaa en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.74606033,  0.93343568, -0.47904799],\n",
       "       [ 0.79447305, -0.24650057, -0.32755651],\n",
       "       [-0.09724706,  0.68051017, -0.75379571],\n",
       "       [ 0.0860524 , -0.25397555, -0.10400635]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.47904799  0.45438769 -1.22510832 -0.29167265  0.          0.93343568\n",
      "  -0.74606033  0.18737534]\n",
      " [-0.32755651 -0.57405708  0.46691654  0.22041597  0.         -0.24650057\n",
      "   0.79447305  0.54797248]\n",
      " [-0.75379571 -0.07328554 -0.85104277 -0.1705326   0.          0.68051017\n",
      "  -0.09724706  0.58326311]\n",
      " [-0.10400635 -0.3579819  -0.01795395 -0.2719295   0.         -0.25397555\n",
      "   0.0860524  -0.16792315]]\n",
      "[[0.38247695 0.61168194 0.22703873 0.42759443 0.5        0.71777179\n",
      "  0.32168034 0.54670726]\n",
      " [0.41883528 0.3603012  0.61465368 0.55488198 0.5        0.43868502\n",
      "  0.68879097 0.63366506]\n",
      " [0.3199948  0.48168681 0.29921416 0.45746987 0.5        0.66385255\n",
      "  0.47570738 0.6418179 ]\n",
      " [0.47402183 0.41144818 0.49551163 0.43243347 0.5        0.43684522\n",
      "  0.52149984 0.45811758]]\n"
     ]
    }
   ],
   "source": [
    "z1 = np.dot(w1, a0) + b1 # (4, 3) * (3, 8) --> (4, 8) 4 filas (neuronas capa 1) * 8 columnas (registros = inputs capa 1)\n",
    "print(z1)\n",
    "a1 = sigmoide(z1)   # (4, 8) 4 filas (neuronas capa 1) * 8 columnas (registros)\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite el proceso con la siguiente capa, que es la capa de salida.\n",
    "En **a2** quedan los resultados de las 8 instancias del set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08278451 -0.00709033  0.31924999  0.24766426  0.16176129  0.07991459\n",
      "   0.40787322  0.32661841]]\n",
      "[[0.52068432 0.49822742 0.57914146 0.56160151 0.54035237 0.51996802\n",
      "  0.60057781 0.58093636]]\n"
     ]
    }
   ],
   "source": [
    "z2 = np.dot(w2, a1) + b2 # (1, 4) * (4, 8) --> (1, 8) 1 filas (neuronas capa 2) * 8 columnas (registros)\n",
    "print(z2)\n",
    "a2 = sigmoide(z2)  # (1, 8) 1 filas (neuronas capa 2) * 8 columnas (registros)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definimos una función llamada **feedForward**, que nos permita realizar este proceso para cualquier capa (diferente de la de entrada), que recibe la matriz de inputs con todos los registros y retorna el vector con las predicciones correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForward(X, w1, b1, w2, b2):\n",
    "    '''Calcula el valor predicho para todos los registros que se encuentran en X\n",
    "       -----------\n",
    "       Argumentos:\n",
    "       X: matriz con los inputs, con tantas filas como atributos y tantas columnas como registros\n",
    "       w1: matriz con los pesos de las conexiones entrantes de la 1a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b1: array con los sesgos de las neuronas de la 1a capa\n",
    "       w2: matriz con los pesos de las conexiones entrantes de la 2a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b2: array con los sesgos de las neuronas de la 2a capa\n",
    "       -----------\n",
    "       Retorna:\n",
    "       a1: matriz con las activaciones de la capa escondida, \n",
    "         con tantas filas como neuronas de la capa y tantas columnas como registros\n",
    "       a2 (y estimado): vector con las predicciones\n",
    "    '''\n",
    "    a0 = X # matriz de 3 filas (inputs) * 8 columnas (registros)\n",
    "    z1 = np.dot(w1, a0) + b1 # (4, 3) * (3, 8) --> (4, 8) 4 filas (neuronas capa 1) * 8 columnas (registros = inputs capa 1)\n",
    "    a1 = sigmoide(z1)   # (4, 8) 4 filas (neuronas capa 1) * 8 columnas (registros)\n",
    "    z2 = np.dot(w2, a1) + b2 # (1, 4) * (4, 8) --> (1, 8) 1 filas (neuronas capa 2) * 8 columnas (registros)\n",
    "    a2 = sigmoide(z2)   # (1, 8) 1 filas (neuronas capa 2) * 8 columnas (registros)\n",
    "    return (a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entonces evaluar el estado inicial de la red (con sus parámetros inicales), y encontrar los mismos resultados que vimos antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52068432]\n",
      " [0.49822742]\n",
      " [0.57914146]\n",
      " [0.56160151]\n",
      " [0.54035237]\n",
      " [0.51996802]\n",
      " [0.60057781]\n",
      " [0.58093636]]\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(a2.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los datos están bastante alejados de la realidad [0, 1, 1, 0, 0, 1, 1, 0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos definir el proceso inverso de back propagation, a través del cuál se pueden ajustar los pesos de la red de manera iterativa, minimizando una función de costo que mide lo lejos de las predicciones con respecto a los valores reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.00000001 # para evitar problemas de overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costoGlobal(y_real, y_est): \n",
    "    '''Calcula el costo global de la predicción con la red actual, comparando la clase real con las probabilidad estimadas\n",
    "       -----------\n",
    "       Argumentos:\n",
    "       y_real: array con las clases reales de los datos\n",
    "       y_est: array con las probabilidades de salida estimadas por la red\n",
    "       -----------\n",
    "       Retorna:\n",
    "       costo: promedio de los costos de cada predicción individual\n",
    "    '''\n",
    "    y_est = np.where(y_est<=0,epsilon,y_est)\n",
    "    y_est = np.where(y_est>=1,1-epsilon,y_est)\n",
    "    \n",
    "    costos = -(np.multiply(y_real, np.log(y_est))) - (np.multiply((1-y_real), np.log(1-y_est))) \n",
    "    # (1, 8) 1 filas * 8 columnas (registros)\n",
    "\n",
    "    return np.abs(np.mean(costos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017260765032634"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costo = costoGlobal(y, a2)\n",
    "costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de back-propagation comienza por calcular el error, comparando la diferencia entre lo que produce la red (**a2**) y lo que se espera como valor real (**y**).\n",
    "Vamos a abusar un poco de la nomenclatura para simplificar la escritura de los gradientes.\n",
    "Por ejemplo, el gradiente de la función de pérdida L con respecto a z2 (agregación de la segunda capa) en vez de notarlo com dL/dz, vamos a notarlo dz. Igual hacemos para referirnos a dL/dw2 como dw2, dL/db2 como db2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=X.shape[1] # Número de instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por definición matemática sabemos que la función de pérdida sigmoide de la última capa tiene la siguiente formula:\n",
    "$$ 𝐿(𝑦 ̂, 𝑦)=𝐿(𝑎^{[2]}, 𝑦)= −𝑦∗log⁡(𝑎^{[2]}) − (1−𝑦) ∗ log⁡(1−𝑎^{[2]})$$\n",
    "De ahí, podemos encontrar el gradiente de la pérdida con respecto a las activaciones de la capa 2:\n",
    "$$\\frac{𝜕L}{𝜕𝑎^{[2]}} = \\frac{−𝑦}{𝑎^{[2]}}  +   \\frac{1−𝑦}{1−𝑎^{[2]}} = \\frac{𝑎^{[2]} −𝑦}{𝑎^{[2]}*(1−𝑎^{[2]})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, como $𝑎^{[2]}=sigmoide(z^{[2]})$, podemos decir que \n",
    "$$\\frac{𝜕𝑎^{[2]}}{𝜕𝑧^{[2]}} = 𝜎^′ (𝑧^{[2]}  )=𝑎^{[2]} * (1−𝑎^{[2]})$$\n",
    "De ahí,\n",
    "$$𝜕𝑧^{[2]} = \\frac{𝜕L^{[2]}}{𝜕𝑧^{[2]}} = \\frac{𝜕L^{[2]}}{𝜕a^{[2]}} * \\frac{𝜕a^{[2]}}{𝜕𝑧^{[2]}}\n",
    "= \\frac{(𝑎^{[2]} −𝑦)}{𝑎^{[2]}⋅(1−𝑎^{[2]})} * 𝑎^{[2]} * (1−𝑎^{[2]})\n",
    "= 𝑎^{[2]} −𝑦\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52068432, -0.50177258, -0.42085854,  0.56160151,  0.54035237,\n",
       "        -0.48003198, -0.39942219,  0.58093636]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz2 = a2-y          # (1, 8) 1 filas * 8 columnas (registros)\n",
    "dz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gradiente dw2 nos indica que la pendiente de la curva de pérdida con respecto a los pesos de la capa 2, de tal manera que podemos actualizarlos siguiendo la siguiente ecuación.\n",
    "\n",
    "Partimos de\n",
    "    $$𝑧^{[2]} = 𝑾^{[𝟐]}* 𝒂^{[𝟏]} + * 𝒃^{[2]} $$\n",
    "Encontramos el gradiente con respecto a los parámetros:\n",
    "    $$\\frac{𝜕𝑧^{[2]}}{𝜕𝑾^{[𝟐]}} = 𝒂^{[𝟏]}$$\n",
    "    $$\\frac{𝜕𝑧^{[2]}}{𝜕𝒃^{[𝟐]}} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De ahí:\n",
    "    $$𝜕𝑾^{[𝟐]} = \\frac{𝜕𝐿}{𝜕𝑾^{[𝟐]}}=\\frac{𝜕𝐿}{𝜕𝑧^{[2]}} * \\frac{𝜕𝑧^{[2]}}{𝜕𝑾^{[𝟐]}} \n",
    "    =𝜕z^{[𝟐]}*𝒂^{[𝟏]}=(𝑎^{[2]} −𝑦)* 𝒂^{[𝟏]}$$\n",
    "    $$𝜕𝒃^{[𝟐]} = \\frac{𝜕𝐿}{𝜕𝒃^{[𝟐]}}=\\frac{𝜕𝐿}{𝜕𝑧^{[2]}} * \\frac{𝜕𝑧^{[2]}}{𝜕𝒃^{[𝟐]}} \n",
    "    =𝜕z^{[𝟐]}*1=(𝑎^{[2]} −𝑦)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01894371 0.03035325 0.02378262 0.02412405]]\n"
     ]
    }
   ],
   "source": [
    "dw2 = (1/m)*np.dot(dz2, a1.T) # (1, 8) * (8, 4) --> (1, 4) 1 fila (neuronas capa 2), 4 inputs\n",
    "print(dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52068432, -0.50177258, -0.42085854,  0.56160151,  0.54035237,\n",
       "        -0.48003198, -0.39942219,  0.58093636]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4014892687908933"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05018616]]\n"
     ]
    }
   ],
   "source": [
    "db2 = (1/m)*np.sum(dz2, axis=1, keepdims=True)  # (1,1) 1 fila (neuronas capa 2) \n",
    "                                                # El axis=1 permita indicar que queremos las columnas\n",
    "                                                # el keepdims=True es para que siga siendo una lista de listas\n",
    "print(db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuamos el back propagation y hacemos lo propio con las neuronas de la primera capa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{𝜕𝒛^{[𝟐]}}{𝜕𝒂^{[𝟏]}} = 𝑾^{[𝟐]} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{𝜕𝐿}{𝜕𝒛^{[𝟏]}} = \\frac{𝜕𝐿}{𝜕𝒂^{[𝟐]}}*\\frac{𝜕𝒂^{[𝟐]}}{𝜕𝒛^{[𝟐]}}*\\frac{𝜕𝒛^{[𝟐]}}{𝜕𝒂^{[𝟏]}}*\\frac{𝜕𝒂^{[𝟏]}}{𝜕𝒛^{[𝟏]}}\n",
    "=(𝑎^{[2]} −𝑦)*𝑾^{[𝟐]}*𝜎^′ (𝑧^{[1]}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(w2.T, dz2) * sigmoideGrad(a1) # (4,1) * (1,8) --> (4, 8) 4 filas (neuronas capa 1), 8 registros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y teniendo en cuenta la agregación de la primera capa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{𝜕𝑧^{[1]}}{𝜕𝑾^{[1]}} = 𝒂^{[0]} = 𝑿$$\n",
    "$$\\frac{𝜕𝑧^{[1]}}{𝜕𝒃^{[1]}} = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01115483 -0.00602118 -0.00624334]\n",
      " [ 0.00794091  0.00357267  0.004509  ]\n",
      " [ 0.00681363  0.0032471   0.00313675]\n",
      " [-0.00285442 -0.00157007 -0.00151429]]\n"
     ]
    }
   ],
   "source": [
    "dw1 = (1/m)*np.dot(dz1, X.T) #(4,8) * (8, 3) --> (4,3) 4 filas (neuronas capa 1), 3 inputs\n",
    "print(dw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01501239]\n",
      " [ 0.01045782]\n",
      " [ 0.00809461]\n",
      " [-0.0037904 ]]\n"
     ]
    }
   ],
   "source": [
    "db1 = (1/m)*np.sum(dz1, axis=1, keepdims=True) # (4,1) 4 filas (neuronas capa 1)\n",
    "print(db1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya se tienen los dw1, dw2, db1 y db2, se podrían actualizar los valores de los parámetros, dado el learning rate definido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función se encarga de encapsular todo el proceso anterior en un solo llamado para facilitar la implementación del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(X, y, w1, b1, w2, b2, a1, a2): \n",
    "    '''Calcula los deltas de las actualizaciones de los parámetros de las capas \n",
    "       -----------\n",
    "       Argumentos:\n",
    "       X: matriz con los inputs, con tantas filas como atributos y tantas columnas como registros\n",
    "       y: array con los valores reales a predecir\n",
    "       w1: matriz con los pesos de las conexiones entrantes de la 1a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       w2: matriz con los pesos de las conexiones entrantes de la 2a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b1: array con los sesgos de las neuronas de la 1a capa\n",
    "       b2: array con los sesgos de las neuronas de la 2a capa\n",
    "       a1: matriz con las activaciones de la capa escondida, con tantas filas como neuronas de la capa y tantas columnas como registros\n",
    "       a2 (y estimado): vector con las predicciones\n",
    "       -----------\n",
    "       Retorna:\n",
    "       dw1: matriz con las actualizaciones que se deben aplicar a los coeficientes de la capa 1 (hidden)\n",
    "       db1: array con las actualizaciones que se deben aplicar a los sesgos de la capa 1 (hidden)\n",
    "       dw2: matriz con las actualizaciones que se deben aplicar a los coeficientes de la capa 2 (salida)\n",
    "       db2: array con las actualizaciones que se deben aplicar a los sesgos de la capa 2 (salida)\n",
    "    '''\n",
    "    m=X.shape[1]\n",
    "    dz2 = a2-y          # (1, 8) 1 filas * 8 columnas (registros)\n",
    "    dw2 = (1/m)*np.dot(dz2, a1.T) # (1, 8) * (8, 4) --> (1, 4) 1 fila (neuronas capa 2), 4 inputs\n",
    "    db2 = (1/m)*np.sum(dz2, axis=1, keepdims=True) # (1,1) 1 fila (neuronas capa 2)\n",
    "\n",
    "    dz1 = np.dot(w2.T, dz2) * sigmoideGrad(a1) # (4,1) * (1,8) --> (4, 8) 4 filas (neuronas capa 1), 8 registros\n",
    "    dw1 = (1/m)*np.dot(dz1, X.T) #(4,8) * (8, 3) --> (4,3) 4 filas (neuronas capa 1), 3 inputs\n",
    "    db1 = (1/m)*np.sum(dz1, axis=1, keepdims=True) # (4,1) 4 filas (neuronas capa 1)\n",
    "\n",
    "    return (dw1, db1, dw2, db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una iteración de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a programar el ciclo (época) de back propagation.\n",
    "- Se calculan los valores intermediarios en la fase forward: a0 (son las entradas X), a1 y a2 (las salidas estimadas y_est)\n",
    "- Se calcula el error de cada época\n",
    "- Se encuentran los valores de los gradientes en la fase backward a partir de los resultados anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender mejor lo que pasa durante el entrenamiento de la red, vamos a ver en detalle lo que pasa con la primera época"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que hacemos es inicializar los pesos y sesgos de la red, así como los parámetros del entrenamiento como la taza de aprendizaje (*learning rate*) y número de épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = initParams()\n",
    "lr = 1 # learning rate\n",
    "epocas = 1000 # Iteraciones de backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un paso de feed forward que nos permita obtener la predicción con los pesos y sesgos actuales (iniciales aleatorios) de la red, que vamos a comparar con los valores reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones actuales son las activaciones de la neurona de la capa de salida a2:\n",
      " [[0.52068432 0.49822742 0.57914146 0.56160151 0.54035237 0.51996802\n",
      "  0.60057781 0.58093636]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son las activaciones de la neurona de la capa de salida a2:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este momento no hay ninguna relación entre las predicciones y los valores reales.\n",
    "Vamos entonces a modificar los parámetros de la red con back propagation. Calculamos las actualizaciones y modificamos los valores iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las actualizaciones son las siguientes:\n",
      "dw1: [[-0.01115483 -0.00602118 -0.00624334]\n",
      " [ 0.00794091  0.00357267  0.004509  ]\n",
      " [ 0.00681363  0.0032471   0.00313675]\n",
      " [-0.00285442 -0.00157007 -0.00151429]] \n",
      "dw2: [[0.01894371 0.03035325 0.02378262 0.02412405]] \n",
      "db1: [[-0.01501239]\n",
      " [ 0.01045782]\n",
      " [ 0.00809461]\n",
      " [-0.0037904 ]] \n",
      "db2: [[0.05018616]]\n"
     ]
    }
   ],
   "source": [
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "print(\"Las actualizaciones son las siguientes:\\ndw1:\", dw1,\"\\ndw2:\", dw2,\"\\ndb1:\", db1,\"\\ndb2:\", db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los valores anteriores de los parámetros de la red eran:\n",
      "w1: [[-0.7349055   0.93945686 -0.47280464]\n",
      " [ 0.78653214 -0.25007324 -0.33206551]\n",
      " [-0.10406068  0.67726307 -0.75693246]\n",
      " [ 0.08890683 -0.25240548 -0.10249206]] \n",
      "w2: [[-0.76006235  0.68940416  0.6169941  -0.32001697]] \n",
      "b1: [[ 0.01501239]\n",
      " [-0.01045782]\n",
      " [-0.00809461]\n",
      " [ 0.0037904 ]] \n",
      "b2: [[-0.05018616]]\n",
      "Los nuevos valores de los parámetros de la red son:\n",
      "w1: [[-0.72375067  0.94547804 -0.4665613 ]\n",
      " [ 0.77859122 -0.25364591 -0.33657451]\n",
      " [-0.11087431  0.67401597 -0.76006922]\n",
      " [ 0.09176125 -0.25083541 -0.10097777]] \n",
      "w2: [[-0.77900605  0.65905091  0.59321148 -0.34414101]] \n",
      "b1: [[ 0.03002477]\n",
      " [-0.02091564]\n",
      " [-0.01618922]\n",
      " [ 0.0075808 ]] \n",
      "b2: [[-0.10037232]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Los valores anteriores de los parámetros de la red eran:\\nw1:\", w1,\"\\nw2:\", w2,\"\\nb1:\", b1,\"\\nb2:\", b2)\n",
    "w1 = w1-lr*dw1\n",
    "w2 = w2-lr*dw2\n",
    "b1 = b1-lr*db1\n",
    "b2 = b2-lr*db2\n",
    "print(\"Los nuevos valores de los parámetros de la red son:\\nw1:\", w1,\"\\nw2:\", w2,\"\\nb1:\", b1,\"\\nb2:\", b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya actualizamos los pesos veamos cuáles serían las nuevas predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones anteriores eran:\n",
      " [[0.47201819 0.44612492 0.52815917 0.50587616 0.48796216 0.46456409\n",
      "  0.54635401 0.52221146]]\n",
      "Las predicciones actuales son:\n",
      " [[0.47201819 0.44612492 0.52815917 0.50587616 0.48796216 0.46456409\n",
      "  0.54635401 0.52221146]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Las predicciones anteriores eran:\\n\", a2)\n",
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como lo que tenemos en la neurona de salida es una probabilidad, vamos a establecer un umbral de decisión en 50%, y a transformarlas en valores categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.where(a2>0.5,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones actuales son:\n",
      " [0 0 1 1 0 0 1 1]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos lo que nos darían una cuantas iteraciones de entrenamiento (época):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones anteriores eran:\n",
      " [[0.47201819 0.44612492 0.52815917 0.50587616 0.48796216 0.46456409\n",
      "  0.54635401 0.52221146]]\n",
      "Las predicciones actuales son:\n",
      " [[0.4730721  0.44761444 0.52853247 0.50644189 0.48930477 0.46639464\n",
      "  0.54687289 0.52309989]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Las predicciones actuales son:\n",
      " [0 0 1 1 0 0 1 1]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "w1 = w1-lr*dw1\n",
    "w2 = w2-lr*dw2\n",
    "b1 = b1-lr*db1\n",
    "b2 = b2-lr*db2\n",
    "print(\"Las predicciones anteriores eran:\\n\", a2)\n",
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones anteriores eran:\n",
      " [[0.4730721  0.44761444 0.52853247 0.50644189 0.48930477 0.46639464\n",
      "  0.54687289 0.52309989]]\n",
      "Las predicciones actuales son:\n",
      " [[0.47364644 0.44857226 0.52843091 0.50647916 0.49011936 0.46764671\n",
      "  0.54687893 0.52341745]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Las predicciones actuales son:\n",
      " [0 0 1 1 0 0 1 1]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "w1 = w1-lr*dw1\n",
    "w2 = w2-lr*dw2\n",
    "b1 = b1-lr*db1\n",
    "b2 = b2-lr*db2\n",
    "print(\"Las predicciones anteriores eran:\\n\", a2)\n",
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones anteriores eran:\n",
      " [[0.47364644 0.44857226 0.52843091 0.50647916 0.49011936 0.46764671\n",
      "  0.54687893 0.52341745]]\n",
      "Las predicciones actuales son:\n",
      " [[0.47398939 0.44926674 0.52810894 0.50626707 0.49067637 0.46860953\n",
      "  0.54664559 0.52346293]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Las predicciones actuales son:\n",
      " [0 0 1 1 0 0 1 1]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "w1 = w1-lr*dw1\n",
    "w2 = w2-lr*dw2\n",
    "b1 = b1-lr*db1\n",
    "b2 = b2-lr*db2\n",
    "print(\"Las predicciones anteriores eran:\\n\", a2)\n",
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones anteriores eran:\n",
      " [[0.47398939 0.44926674 0.52810894 0.50626707 0.49067637 0.46860953\n",
      "  0.54664559 0.52346293]]\n",
      "Las predicciones actuales son:\n",
      " [[0.47422038 0.44982741 0.52768872 0.5059398  0.49110605 0.46942277\n",
      "  0.54630414 0.52337998]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Las predicciones actuales son:\n",
      " [0 0 1 1 0 0 1 1]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "w1 = w1-lr*dw1\n",
    "w2 = w2-lr*dw2\n",
    "b1 = b1-lr*db1\n",
    "b2 = b2-lr*db2\n",
    "print(\"Las predicciones anteriores eran:\\n\", a2)\n",
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones anteriores eran:\n",
      " [[0.47422038 0.44982741 0.52768872 0.5059398  0.49110605 0.46942277\n",
      "  0.54630414 0.52337998]]\n",
      "Las predicciones actuales son:\n",
      " [[0.47439688 0.45031684 0.52722875 0.5055617  0.49147114 0.47015398\n",
      "  0.54591747 0.52323754]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Las predicciones actuales son:\n",
      " [0 0 1 1 0 0 1 1]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "w1 = w1-lr*dw1\n",
    "w2 = w2-lr*dw2\n",
    "b1 = b1-lr*db1\n",
    "b2 = b2-lr*db2\n",
    "print(\"Las predicciones anteriores eran:\\n\", a2)\n",
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones anteriores eran:\n",
      " [[0.47439688 0.45031684 0.52722875 0.5055617  0.49147114 0.47015398\n",
      "  0.54591747 0.52323754]]\n",
      "Las predicciones actuales son:\n",
      " [[0.47454649 0.45076534 0.52675692 0.50516355 0.49180187 0.47083599\n",
      "  0.54551556 0.52306866]]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Las predicciones actuales son:\n",
      " [0 0 1 1 0 0 1 1]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "w1 = w1-lr*dw1\n",
    "w2 = w2-lr*dw2\n",
    "b1 = b1-lr*db1\n",
    "b2 = b2-lr*db2\n",
    "print(\"Las predicciones anteriores eran:\\n\", a2)\n",
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", a2)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciclo de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos explicado lo que pasa durante una época de entrenamiento, podemos definir una función de entrenamiento que se repita para cada época. Definimos los hiperparámetros del modelo, utilizados para aprender los pesos de las capas (los verdaderos parámetros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarRed(epocas, lr, X, y, w1, b1, w2, b2, a1, a2, echo_progression=True):\n",
    "    '''Se encarga de controlar el ciclo de aprendizaje de los parámetros de la red\n",
    "       -----------\n",
    "       Argumentos:\n",
    "       epocas: número de iteraciones de aprendizaje a calcular \n",
    "       lr: (learning rate) tasa de aprendizaje que controla la magnitud de la actualización de los parámetros cada iteración\n",
    "       X: matriz con los inputs, con tantas filas como atributos y tantas columnas como registros\n",
    "       y: array con los valores reales a predecir\n",
    "       w1: matriz con los pesos de las conexiones entrantes de la 1a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       w2: matriz con los pesos de las conexiones entrantes de la 2a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b1: array con los sesgos de las neuronas de la 1a capa\n",
    "       b2: array con los sesgos de las neuronas de la 2a capa\n",
    "       a1: matriz con las activaciones de la capa escondida, con tantas filas como neuronas de la capa y tantas columnas como registros\n",
    "       a2 (y estimado): vector con las predicciones\n",
    "       echo_progression: indica si se desea que se imprima el progreso de la tarea\n",
    "       -----------\n",
    "       Retorna:\n",
    "       costos: array con la evolución del costo de la red despúes de la actualización de cada época\n",
    "       accuracies: array con la evolución de la exactitud de la red despúes de la actualización de cada época \n",
    "       dw1: matriz con las actualizaciones que se deben aplicar a los coeficientes de la capa 1 (hidden)\n",
    "       db1: array con las actualizaciones que se deben aplicar a los sesgos de la capa 1 (hidden)\n",
    "       dw2: matriz con las actualizaciones que se deben aplicar a los coeficientes de la capa 2 (salida)\n",
    "       db2: array con las actualizaciones que se deben aplicar a los sesgos de la capa 2 (salida)\n",
    "    '''\n",
    "    costos = []\n",
    "    accuracies = []\n",
    "    for i in range(epocas):\n",
    "        a1, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "        dw1, db1, dw2, db2 = backProp(X, y, w1, b1, w2, b2, a1, a2)\n",
    "\n",
    "        # Actualización de los parámetros\n",
    "        w1 -= lr*dw1\n",
    "        w2 -= lr*dw2\n",
    "        b1 -= lr*db1\n",
    "        b2 -= lr*db2\n",
    "        \n",
    "        #Costo y accuracy (usa el feed forward para obtener la predicción y luego calcula el accuracy)\n",
    "        #Se deben guardar los costos y accuracies en los vectores que se retornarán al final\n",
    "        _, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "        y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "        accuracy = accuracy_score(y_pred, y)        \n",
    "        accuracies.append(accuracy)\n",
    "        costo = costoGlobal(y, a2)\n",
    "        costos.append(costo)\n",
    "        \n",
    "        if (echo_progression & (i%10==0)):\n",
    "            print(\"Epoca %d, costo = %12.10f, accuracy=%12.10f\" % (i, costo, accuracy))\n",
    "    \n",
    "    return (costos, accuracies, w1, b1, w2, b2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los hyperparámetros del modelo, utilizados para aprender los pesos de las capas (los verdaderos parámetros) y lanzamos el entrenamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0, costo = 0.6974323856, accuracy=0.3750000000\n",
      "Epoca 10, costo = 0.6948107134, accuracy=0.5000000000\n",
      "Epoca 20, costo = 0.6938142023, accuracy=0.5000000000\n",
      "Epoca 30, costo = 0.6930380901, accuracy=0.6250000000\n",
      "Epoca 40, costo = 0.6923781649, accuracy=0.6250000000\n",
      "Epoca 50, costo = 0.6917624945, accuracy=0.5000000000\n",
      "Epoca 60, costo = 0.6911359616, accuracy=0.5000000000\n",
      "Epoca 70, costo = 0.6904503749, accuracy=0.5000000000\n",
      "Epoca 80, costo = 0.6896572964, accuracy=0.5000000000\n",
      "Epoca 90, costo = 0.6887018733, accuracy=0.5000000000\n",
      "Epoca 100, costo = 0.6875164854, accuracy=0.5000000000\n",
      "Epoca 110, costo = 0.6860132125, accuracy=0.5000000000\n",
      "Epoca 120, costo = 0.6840741001, accuracy=0.5000000000\n",
      "Epoca 130, costo = 0.6815380328, accuracy=0.5000000000\n",
      "Epoca 140, costo = 0.6781827277, accuracy=0.5000000000\n",
      "Epoca 150, costo = 0.6737000475, accuracy=0.6250000000\n",
      "Epoca 160, costo = 0.6676627698, accuracy=0.6250000000\n",
      "Epoca 170, costo = 0.6594819722, accuracy=0.7500000000\n",
      "Epoca 180, costo = 0.6483583571, accuracy=0.7500000000\n",
      "Epoca 190, costo = 0.6332426197, accuracy=0.8750000000\n",
      "Epoca 200, costo = 0.6128470549, accuracy=0.8750000000\n",
      "Epoca 210, costo = 0.5857973579, accuracy=0.8750000000\n",
      "Epoca 220, costo = 0.5510472727, accuracy=0.8750000000\n",
      "Epoca 230, costo = 0.5085739402, accuracy=1.0000000000\n",
      "Epoca 240, costo = 0.4600099097, accuracy=1.0000000000\n",
      "Epoca 250, costo = 0.4085609205, accuracy=1.0000000000\n",
      "Epoca 260, costo = 0.3579846313, accuracy=1.0000000000\n",
      "Epoca 270, costo = 0.3113225384, accuracy=1.0000000000\n",
      "Epoca 280, costo = 0.2702491876, accuracy=1.0000000000\n",
      "Epoca 290, costo = 0.2351834736, accuracy=1.0000000000\n",
      "Epoca 300, costo = 0.2057519682, accuracy=1.0000000000\n",
      "Epoca 310, costo = 0.1812268304, accuracy=1.0000000000\n",
      "Epoca 320, costo = 0.1608044493, accuracy=1.0000000000\n",
      "Epoca 330, costo = 0.1437419031, accuracy=1.0000000000\n",
      "Epoca 340, costo = 0.1294059097, accuracy=1.0000000000\n",
      "Epoca 350, costo = 0.1172781973, accuracy=1.0000000000\n",
      "Epoca 360, costo = 0.1069430899, accuracy=1.0000000000\n",
      "Epoca 370, costo = 0.0980700931, accuracy=1.0000000000\n",
      "Epoca 380, costo = 0.0903969776, accuracy=1.0000000000\n",
      "Epoca 390, costo = 0.0837152823, accuracy=1.0000000000\n",
      "Epoca 400, costo = 0.0778585848, accuracy=1.0000000000\n",
      "Epoca 410, costo = 0.0726932783, accuracy=1.0000000000\n",
      "Epoca 420, costo = 0.0681114206, accuracy=1.0000000000\n",
      "Epoca 430, costo = 0.0640252203, accuracy=1.0000000000\n",
      "Epoca 440, costo = 0.0603627912, accuracy=1.0000000000\n",
      "Epoca 450, costo = 0.0570648751, accuracy=1.0000000000\n",
      "Epoca 460, costo = 0.0540823032, accuracy=1.0000000000\n",
      "Epoca 470, costo = 0.0513740196, accuracy=1.0000000000\n",
      "Epoca 480, costo = 0.0489055344, accuracy=1.0000000000\n",
      "Epoca 490, costo = 0.0466477048, accuracy=1.0000000000\n",
      "Epoca 500, costo = 0.0445757695, accuracy=1.0000000000\n",
      "Epoca 510, costo = 0.0426685795, accuracy=1.0000000000\n",
      "Epoca 520, costo = 0.0409079798, accuracy=1.0000000000\n",
      "Epoca 530, costo = 0.0392783121, accuracy=1.0000000000\n",
      "Epoca 540, costo = 0.0377660101, accuracy=1.0000000000\n",
      "Epoca 550, costo = 0.0363592693, accuracy=1.0000000000\n",
      "Epoca 560, costo = 0.0350477769, accuracy=1.0000000000\n",
      "Epoca 570, costo = 0.0338224880, accuracy=1.0000000000\n",
      "Epoca 580, costo = 0.0326754407, accuracy=1.0000000000\n",
      "Epoca 590, costo = 0.0315996019, accuracy=1.0000000000\n",
      "Epoca 600, costo = 0.0305887381, accuracy=1.0000000000\n",
      "Epoca 610, costo = 0.0296373074, accuracy=1.0000000000\n",
      "Epoca 620, costo = 0.0287403671, accuracy=1.0000000000\n",
      "Epoca 630, costo = 0.0278934970, accuracy=1.0000000000\n",
      "Epoca 640, costo = 0.0270927328, accuracy=1.0000000000\n",
      "Epoca 650, costo = 0.0263345100, accuracy=1.0000000000\n",
      "Epoca 660, costo = 0.0256156152, accuracy=1.0000000000\n",
      "Epoca 670, costo = 0.0249331449, accuracy=1.0000000000\n",
      "Epoca 680, costo = 0.0242844693, accuracy=1.0000000000\n",
      "Epoca 690, costo = 0.0236672015, accuracy=1.0000000000\n",
      "Epoca 700, costo = 0.0230791703, accuracy=1.0000000000\n",
      "Epoca 710, costo = 0.0225183966, accuracy=1.0000000000\n",
      "Epoca 720, costo = 0.0219830731, accuracy=1.0000000000\n",
      "Epoca 730, costo = 0.0214715464, accuracy=1.0000000000\n",
      "Epoca 740, costo = 0.0209823009, accuracy=1.0000000000\n",
      "Epoca 750, costo = 0.0205139448, accuracy=1.0000000000\n",
      "Epoca 760, costo = 0.0200651984, accuracy=1.0000000000\n",
      "Epoca 770, costo = 0.0196348826, accuracy=1.0000000000\n",
      "Epoca 780, costo = 0.0192219097, accuracy=1.0000000000\n",
      "Epoca 790, costo = 0.0188252747, accuracy=1.0000000000\n",
      "Epoca 800, costo = 0.0184440475, accuracy=1.0000000000\n",
      "Epoca 810, costo = 0.0180773664, accuracy=1.0000000000\n",
      "Epoca 820, costo = 0.0177244318, accuracy=1.0000000000\n",
      "Epoca 830, costo = 0.0173845010, accuracy=1.0000000000\n",
      "Epoca 840, costo = 0.0170568828, accuracy=1.0000000000\n",
      "Epoca 850, costo = 0.0167409338, accuracy=1.0000000000\n",
      "Epoca 860, costo = 0.0164360538, accuracy=1.0000000000\n",
      "Epoca 870, costo = 0.0161416828, accuracy=1.0000000000\n",
      "Epoca 880, costo = 0.0158572972, accuracy=1.0000000000\n",
      "Epoca 890, costo = 0.0155824072, accuracy=1.0000000000\n",
      "Epoca 900, costo = 0.0153165542, accuracy=1.0000000000\n",
      "Epoca 910, costo = 0.0150593083, accuracy=1.0000000000\n",
      "Epoca 920, costo = 0.0148102661, accuracy=1.0000000000\n",
      "Epoca 930, costo = 0.0145690485, accuracy=1.0000000000\n",
      "Epoca 940, costo = 0.0143352993, accuracy=1.0000000000\n",
      "Epoca 950, costo = 0.0141086834, accuracy=1.0000000000\n",
      "Epoca 960, costo = 0.0138888850, accuracy=1.0000000000\n",
      "Epoca 970, costo = 0.0136756066, accuracy=1.0000000000\n",
      "Epoca 980, costo = 0.0134685676, accuracy=1.0000000000\n",
      "Epoca 990, costo = 0.0132675028, accuracy=1.0000000000\n"
     ]
    }
   ],
   "source": [
    "lr = 1 # learning rate\n",
    "epocas = 1000 # Iteraciones de backpropagation\n",
    "\n",
    "w1, b1, w2, b2 = initParams()\n",
    "accuracies, costos, w1, b1, w2, b2 = entrenarRed(epocas, lr, X, y, w1, b1, w2, b2, a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestras predicciones finales son: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones actuales son:\n",
      " [0.01119753 0.98752439 0.98518618 0.01316119 0.01143432 0.98770127\n",
      " 0.98535006 0.01401101]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Las predicciones actuales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "Los valores reales son:\n",
      " [0 1 1 0 0 1 1 0]\n",
      "El accuracy actual es de :\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "_, a2 = feedForward(X, w1, b1, w2, b2)\n",
    "print(\"Las predicciones actuales son:\\n\", np.squeeze(a2))\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "y_pred = np.squeeze(np.where(a2>0.5,1,0))\n",
    "print(\"Las predicciones actuales son:\\n\", y_pred)\n",
    "print(\"Los valores reales son:\\n\", y)\n",
    "accuracy = accuracy_score(y_pred, y)\n",
    "print(\"El accuracy actual es de :\\n\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar el mejor learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRates = np.arange(0, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.0 , costo:  0.7017260765032634 , accuracy:  0.375\n",
      "LR:  0.1 , costo:  0.6875540686783325 , accuracy:  0.5\n",
      "LR:  0.2 , costo:  0.6121044003321474 , accuracy:  0.875\n",
      "LR:  0.30000000000000004 , costo:  0.20519893193490535 , accuracy:  1.0\n",
      "LR:  0.4 , costo:  0.077948473425928 , accuracy:  1.0\n",
      "LR:  0.5 , costo:  0.0446527061777364 , accuracy:  1.0\n",
      "LR:  0.6000000000000001 , costo:  0.03064170818629123 , accuracy:  1.0\n",
      "LR:  0.7000000000000001 , costo:  0.0231172367819532 , accuracy:  1.0\n",
      "LR:  0.8 , costo:  0.01847302065184806 , accuracy:  1.0\n",
      "LR:  0.9 , costo:  0.015339725265469669 , accuracy:  1.0\n",
      "LR:  1.0 , costo:  0.013091445417201038 , accuracy:  1.0\n",
      "LR:  1.1 , costo:  0.011403744144878113 , accuracy:  1.0\n",
      "LR:  1.2000000000000002 , costo:  0.010092455060701758 , accuracy:  1.0\n",
      "LR:  1.3 , costo:  0.009045599260370987 , accuracy:  1.0\n",
      "LR:  1.4000000000000001 , costo:  0.008191325440908438 , accuracy:  1.0\n",
      "LR:  1.5 , costo:  0.007481490018496194 , accuracy:  1.0\n",
      "LR:  1.6 , costo:  0.006882665506379397 , accuracy:  1.0\n",
      "LR:  1.7000000000000002 , costo:  0.006370940340261828 , accuracy:  1.0\n",
      "LR:  1.8 , costo:  0.005928771665008553 , accuracy:  1.0\n",
      "LR:  1.9000000000000001 , costo:  0.005543006027546137 , accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "costosFinales = []\n",
    "accuraciesFinales = []\n",
    "\n",
    "for lr in learningRates:\n",
    "    w1, b1, w2, b2 = initParams()\n",
    "    costos, accuracies, w1, b1, w2, b2 = entrenarRed(epocas, lr, X, y, w1, b1, w2, b2, a1, a2, False)\n",
    "    costosFinales.append(costos[epocas-1])\n",
    "    accuraciesFinales.append(accuracies[epocas-1])\n",
    "    print(\"LR: \", lr, \", costo: \", costos[epocas-1], \", accuracy: \", accuracies[epocas-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "costosFinales = np.array(costosFinales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "ax = plt.gca()\n",
    "plt.plot(learningRates, costosFinales)\n",
    "#ax.set_xscale('log')\n",
    "#ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Costo')\n",
    "plt.title('Costo con respecto al learning rate')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
