{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentos de analítica 2 (clase 4) - Diego Fernando Agudelo - Universidad ICESI - diegoagudelo30@gmail.com\n",
    "\n",
    "# Fundamentos-analitica-II\n",
    "Repositorio de trabajos para la asignatura de la maestría en Ciencia de Datos\n",
    "\n",
    "FACULTAD DE INGENIERÍA, DISEÑO Y CIENCIAS \n",
    "APLICADAS \n",
    "MAESTRÍA EN CIENCIA DE DATOS \n",
    "TIC 60153 – Fundamentos de analítica II \n",
    "\n",
    "Grupo: \n",
    "\n",
    "**DANIEL DELGADO - FABIAN SALAZAR FIGUEROA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En días recientes trabajamos con una compañía de comestibles que estaba interesada en predecir el comportamiento de las ventas (en unidades) de sus dos productos estrella. Fuimos contratados para generar un modelo que permita pronosticar las ventas del siguiente mes de cada uno de esos dos productos. La base de datos disponible en el archivo Examen.csv tiene la información de cada uno de los productos desde enero de 2008.\n",
    "\n",
    "Su misión es encontrar el mejor modelo para pronosticar cada una de las series. Usted debe entregar un informe escrito de no más de cuatro páginas que presente los resultados al cliente y cuente el proceso para llegar a los pronósticos. Vea las instrucciones para asegurar que entrega los archivos requeridos\n",
    "\n",
    "### Instrucciones\n",
    "El examen se compone de dos partes:\n",
    "- La primera corresponde a una parte de selección múltiple con 19 preguntas que se responderán en el salón de clase en 45 minutos. Esa primera parte tiene una calificación de 1 a 5.\n",
    "-La segunda parte corresponde a la parte práctica del examen y tiene también una calificación de 1 a 5.\n",
    "\n",
    "- La nota de este examen parcial corresponderá al promedio ponderado de las dos notas, donde la parte práctica tiene un peso de 40 % y la parte de selección múltiple de 60 %.\n",
    "- Usted tiene hasta el 15 de Septiembre a las 12:00 pm para enviar los archivos por correo, estos archivos deben tener su nombre.\n",
    "- Sólo se calificaran exámenes en formato pdf. Cualquier otro formato no será tenido en cuenta.\n",
    "- El examen debe estar acompañado de un notebook (ipynb)  que incluya todo los códigos de python que se emplean para obtener sus resultados.\n",
    "- El nombre del archivo debe tener su nombre. No se recibirán archivos en otro formato.\n",
    "- Esta parte del examen es para realizar en casa y debe reflejar el trabajo individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Carga de paquetes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Operaciones con dataframes\n",
    "from matplotlib import pyplot as plt # gráficos\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose # descomposición de series\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing  # Holwinters simple\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing # Holwinters doble y tripe\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#!pip install fastai wwf bayesian-optimization -q --upgrade\n",
    "from bayes_opt import BayesianOptimization\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Ignorar advertencias de futuro, usuario, y convergencia (comunes en modelos como ARIMA)\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Carga de datos**\n",
    "\n",
    "Nuestra primera tarea será leer el archivo csv. Para eso podemos emplear el paquete Pandas. Carguemos los datos en un objeto que denominaremos data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"https://raw.githubusercontent.com/alfa7g7/Fundamentos-analitica-II/main/UNIDAD%20I/Clase%204/Examen.csv\", sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimiendo el tamano del dataframe\n",
    "print(data.shape)\n",
    "\n",
    "# Graficando los datos de producto1 y produto2\n",
    "plt.title(\"Tasa de ventas del producto 1\")\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Ventas mensuales\")\n",
    "plt.plot(data[[\"producto1\"]])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Tasa de ventas del producto 2\")\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Ventas mensuales\")\n",
    "plt.plot(data[[\"producto2\"]])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Procedemos a hacer un análisis corto de EDA para verificar tamaño del conjunto de datos para cada serie de tiempo, nulos (si hay) y algunas cuantificaciones estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinamos si existen nulos en las series de tiempo\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadsiticas del conjunto de datos de tendencia central\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ahora debemos convertir en índice la variable sin nombre: 'Unnamed: 0'  que representa los meses desde enero del 2008 como lo indica el enunciado del problema y expresarla en forma de fecha para mejorar el entendimiento y procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar la columna 'Unnamed: 0' a 'Mes'\n",
    "data.rename(columns={'Unnamed: 0': 'Mes'}, inplace=True)\n",
    "\n",
    "# Función para convertir un número de mes a la última fecha de cada mes\n",
    "def convertir_mes_a_fecha_final(mes, start_date):\n",
    "    year = start_date.year + (mes - 1) // 12\n",
    "    month = (start_date.month + (mes - 1) % 12 - 1) % 12 + 1\n",
    "    #Obtener el último día del mes\n",
    "    last_day = monthrange(year, month)[1]\n",
    "    return datetime(year, month, last_day)\n",
    "\n",
    "# Fecha de inicio (enero de 2008)\n",
    "start_date = datetime(2008, 1, 1)\n",
    "\n",
    "# Aplicar la función a la columna 'Mes'\n",
    "data['Mes'] = data['Mes'].apply(lambda x: convertir_mes_a_fecha_final(x, start_date))\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer la columna 'Mes' como índice\n",
    "data.set_index('Mes', inplace=True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miramos nuevamente como queda el dataframe con estas transformaciones\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinamos si existen nulos en las series de tiempo\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadsiticas del conjunto de datos de tendencia central\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ya con esta pequeñas transformaciones tenemos nuestro conjunto de datos listo para trabajarlo y proceder a hacer todo lo necesario para llevar a cabo los pronósticos de cada serie de tiempo de los dos prodcutos estrellas de la empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimiendo el tamano del dataframe\n",
    "print(data.shape)\n",
    "\n",
    "# Graficando los datos de producto1 y produto2\n",
    "plt.title(\"Tasa de ventas del producto 1\")\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Ventas mensuales\")\n",
    "plt.plot(data[[\"producto1\"]])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Tasa de ventas del producto 2\")\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Ventas mensuales\")\n",
    "plt.plot(data[[\"producto2\"]])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Encontrando los componentes de las series de tiempo para los productos 1 y 2\n",
    "\n",
    "En algunas ocasiones puede ser útil empezar nuestro análisis descomponiendo la serie de tiempo en sus componentes: **tendencia**, **estacionalidad** y **componente puramente aleatorio**. Una forma de hacer esto es empleando la función seasonal_decompose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Componentes serie de tiempo prodcuto1\n",
    "td_componentes_producto1 = seasonal_decompose(data[[\"producto1\"]],model=\"additive\")\n",
    "fig = td_componentes_producto1.plot()\n",
    "fig.set_size_inches((16, 9))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podemos observar el componente estacional marcado en la serie de producto1, una tendencia no lineal de los datos y la parte aleatoria.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos cada componente de la serie de tiempo del producto1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_componentes_producto1.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_componentes_producto1.trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_componentes_producto1.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Componentes serie de tiempo prodcuto2\n",
    "td_componentes_producto2 = seasonal_decompose(data[[\"producto2\"]],model=\"additive\")\n",
    "fig = td_componentes_producto2.plot()\n",
    "fig.set_size_inches((16, 9))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podemos observar el componente estacional marcado en la serie producto2, una tendencia no lineal de los datos y la parte aleatoria.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos cada componente de la serie de tiempo del producto2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_componentes_producto2.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_componentes_producto2.trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_componentes_producto2.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a realizar una gráfica para comparar ambas series donde vemos el comportamiento de cada producto respecto al otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear subplots\n",
    "fig, axes = plt.subplots(4, 2, figsize=(18, 12))\n",
    "\n",
    "# Graficar los componentes de producto1\n",
    "axes[0, 0].plot(td_componentes_producto1.observed)\n",
    "axes[0, 0].set_title('Producto 1 - Observado')\n",
    "axes[1, 0].plot(td_componentes_producto1.trend)\n",
    "axes[1, 0].set_title('Producto 1 - Tendencia')\n",
    "axes[2, 0].plot(td_componentes_producto1.seasonal)\n",
    "axes[2, 0].set_title('Producto 1 - Estacionalidad')\n",
    "axes[3, 0].plot(td_componentes_producto1.resid)\n",
    "axes[3, 0].set_title('Producto 1 - Residual')\n",
    "\n",
    "# Graficar los componentes de producto2\n",
    "axes[0, 1].plot(td_componentes_producto2.observed)\n",
    "axes[0, 1].set_title('Producto 2 - Observado')\n",
    "axes[1, 1].plot(td_componentes_producto2.trend)\n",
    "axes[1, 1].set_title('Producto 2 - Tendencia')\n",
    "axes[2, 1].plot(td_componentes_producto2.seasonal)\n",
    "axes[2, 1].set_title('Producto 2 - Estacionalidad')\n",
    "axes[3, 1].plot(td_componentes_producto2.resid)\n",
    "axes[3, 1].set_title('Producto 2 - Residual')\n",
    "\n",
    "# Ajustar el layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí notamos que la tendencia de cada producto ha sido inversa es decir: el producto1 tiene una tendencia hacia la baja y el producto2 una tendencia a la alza; pero debemos observar que también a pesar de esto al final ambos prodcutos se encuentran en una ventas similares en cantidad aunque aún vende más el producto1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. PROTOCOLOS DE EVALUACION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al inicio había hecho un train y test donde el test tenía solo el ultimo dato, pensando en los ejercicios anteriores.. NOta! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Ventana Recursiva**\n",
    "\n",
    "En un enfoque de ventana recursiva, entrenas el modelo con un conjunto de datos y luego lo usas para predecir un punto en el futuro. Después de obtener la predicción, amplías la ventana para incluir este nuevo punto y repites el proceso.\n",
    "\n",
    "![alt text](recursive-window.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Rolling window**\n",
    "\n",
    "En una rolling window, mueves la ventana a lo largo del tiempo para generar predicciones, entrenando el modelo solo en los datos más recientes.\n",
    "\n",
    "![image.png](rolling-window.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo del modelo a usar se deben hacer algunos ajustes a las funciones para el correcto funcionamiento del protocolo de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementan las funciones para evaluar los modelos utilizando ambos protocolos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular RMSE\n",
    "def calculate_rmse(true_values, predictions):\n",
    "    return np.sqrt(mean_squared_error(true_values, predictions))\n",
    "\n",
    "# Evaluación con Ventana Recursiva\n",
    "def recursive_window_evaluation(series, model_func, params, initial_train_size=12):\n",
    "    predictions = []\n",
    "    train = series[:initial_train_size].copy()\n",
    "    \n",
    "    for i in range(initial_train_size, len(series)):\n",
    "        model = model_func(train, **params)\n",
    "        if isinstance(model, pd.Series) and not model.empty:\n",
    "            forecast = model.iloc[-1]  # Usar el último valor del promedio móvil\n",
    "        else:\n",
    "            forecast = train.iloc[-1]  # Si no hay suficientes datos para un promedio móvil, usar el último valor de entrenamiento\n",
    "        predictions.append(forecast)\n",
    "        # Concatenar el nuevo valor a la serie de entrenamiento\n",
    "        train = pd.concat([train, series[i:i+1]])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Evaluación con Rolling Window ajustada\n",
    "def rolling_window_evaluation(series, model_func, params, window_size=12):\n",
    "    predictions = []\n",
    "    for i in range(window_size, len(series)):\n",
    "        train = series[:i]\n",
    "        test = series[i:i+1]\n",
    "        \n",
    "        model = model_func(train, **params)\n",
    "        \n",
    "        if isinstance(model, pd.Series) and not model.empty:\n",
    "            forecast = model.iloc[-1]  # Usar el último valor del promedio móvil\n",
    "        else:\n",
    "            forecast = train.iloc[-1]  # Si no hay suficientes datos, usar el último valor de entrenamiento\n",
    "        predictions.append(forecast)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. MODELOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementaremos funciones para:\n",
    "\n",
    "- Promedio Móvil.\n",
    "\n",
    "- Suavización Exponencial (Simple, Holt, Holt-Winters).\n",
    "\n",
    "- Regresion (Polinomios + Estacionalidad)\n",
    "\n",
    "- ARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 PROMEDIO MOVIL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de promedio móvil\n",
    "def moving_average_model(series, window):\n",
    "    # Calcular el promedio móvil\n",
    "    return series.rolling(window=window).mean()\n",
    "\n",
    "# Función para evaluar el modelo de promedio móvil\n",
    "def evaluate_moving_average(data, series_name, window, evaluation_protocol, initial_train_size=12, window_size=12):\n",
    "    series = data[series_name]\n",
    "    params = {'window': window}\n",
    "\n",
    "    # Escoger el protocolo de evaluación\n",
    "    if evaluation_protocol == 'recursive':\n",
    "        predictions = recursive_window_evaluation(series, moving_average_model, params, initial_train_size=initial_train_size)\n",
    "    elif evaluation_protocol == 'rolling':\n",
    "        predictions = rolling_window_evaluation(series, moving_average_model, params, window_size=window_size)\n",
    "    else:\n",
    "        raise ValueError(\"El protocolo de evaluación debe ser 'recursive' o 'rolling'\")\n",
    "    \n",
    "    # Calcular RMSE\n",
    "    true_values = series[initial_train_size:] if evaluation_protocol == 'recursive' else series[window_size:]\n",
    "    rmse = calculate_rmse(true_values, predictions)\n",
    "    \n",
    "    return rmse, predictions\n",
    "\n",
    "# Definir el dataframe para almacenar los resultados\n",
    "results_df = pd.DataFrame(columns=['Series', 'Window', 'Protocol', 'RMSE'])\n",
    "\n",
    "# Función para evaluar diferentes ventanas y almacenar los resultados\n",
    "def evaluate_moving_average_models(data, series_name, windows, protocols):\n",
    "    for window in windows:\n",
    "        for protocol in protocols:\n",
    "            rmse, _ = evaluate_moving_average(data, series_name, window, evaluation_protocol=protocol)\n",
    "            results_df.loc[len(results_df)] = [series_name, window, protocol, rmse]\n",
    "\n",
    "# Listas de ventanas y protocolos a evaluar\n",
    "windows = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Puedes ajustar las ventanas que desees evaluar\n",
    "protocols = ['recursive', 'rolling']\n",
    "\n",
    "# Evaluar las series producto1 y producto2\n",
    "evaluate_moving_average_models(data, 'producto1', windows, protocols)\n",
    "evaluate_moving_average_models(data, 'producto2', windows, protocols)\n",
    "\n",
    "# Seleccionar el mejor modelo para cada serie\n",
    "def select_best_model(results_df, series_name):\n",
    "    best_model = results_df[results_df['Series'] == series_name].sort_values(by='RMSE').iloc[0]\n",
    "    return best_model\n",
    "\n",
    "# Seleccionar el mejor modelo para producto1 y producto2\n",
    "best_model_producto1 = select_best_model(results_df, 'producto1')\n",
    "best_model_producto2 = select_best_model(results_df, 'producto2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor modelo para producto1 es:\\n{best_model_producto1}\\n\")\n",
    "print(f\"El mejor modelo para producto2 es:\\n{best_model_producto2}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pronosticar un mes hacia adelante con el mejor modelo\n",
    "def forecast_one_step_ahead(data, series_name, best_model):\n",
    "    window = best_model['Window']\n",
    "    series = data[series_name]\n",
    "    model = moving_average_model(series, window)\n",
    "    \n",
    "    # Pronosticar el siguiente mes (último valor de la serie con promedio móvil)\n",
    "    forecast = model.iloc[-1]  # Último valor del promedio móvil\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "# Pronóstico de un mes hacia adelante para producto1 y producto2\n",
    "forecast_producto1 = forecast_one_step_ahead(data, 'producto1', best_model_producto1)\n",
    "forecast_producto2 = forecast_one_step_ahead(data, 'producto2', best_model_producto2)\n",
    "\n",
    "\n",
    "# Graficar las predicciones y pronósticos\n",
    "def plot_predictions_and_forecast(series_name, predictions, forecast):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    series = data[series_name]\n",
    "    plt.plot(series.index, series, label='Datos reales')\n",
    "    plt.plot(series.index[len(series)-len(predictions):], predictions, label='Predicciones')\n",
    "    plt.axhline(y=forecast, color='r', linestyle='--', label='Pronóstico 1 mes adelante')\n",
    "    plt.title(f\"Predicciones y pronóstico para {series_name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Obtener las predicciones con el mejor modelo\n",
    "_, predictions_producto1 = evaluate_moving_average(data, 'producto1', best_model_producto1['Window'], best_model_producto1['Protocol'])\n",
    "_, predictions_producto2 = evaluate_moving_average(data, 'producto2', best_model_producto2['Window'], best_model_producto2['Protocol'])\n",
    "\n",
    "# Graficar los resultados para producto1\n",
    "plot_predictions_and_forecast('producto1', predictions_producto1, forecast_producto1)\n",
    "\n",
    "# Graficar los resultados para producto2\n",
    "plot_predictions_and_forecast('producto2', predictions_producto2, forecast_producto2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pronóstico un mes adelante para producto1: {forecast_producto1}\")\n",
    "print(f\"Pronóstico un mes adelante para producto2: {forecast_producto2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
